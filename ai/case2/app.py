import streamlit as st
from utils import init_llm, embed_file, keyword_retriever, place_retriever, save_message, send_message, paint_history
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from prompts import prompt_keyword, prompt_place

st.set_page_config(
    page_title="TraveTalk",
    page_icon="ğŸŒ",
)

llm = init_llm(chat_callback=True)

st.title("ğŸï¸TraveTalk")

st.markdown(
    """
ë°˜ê°‘ìŠµë‹ˆë‹¤!

TraveTalkì€ í‚¤ì›Œë“œ ê¸°ë°˜ ì—¬í–‰ì§€ ì¶”ì²œí•´ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
"""
)

# keyword file upload
with st.sidebar:
    st.write("Keyword fileì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")
    file = st.file_uploader(
        "Upload a .txt .pdf or .docx file",
        type=["pdf", "txt", "docx"],
    )

if file:
    retriever = embed_file(file)
    keyword_retriever = keyword_retriever()
    place_retriever = place_retriever()
    send_message("í‚¤ì›Œë“œë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¥ì†Œë¥¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?", "ai", save=False)
    paint_history()
    message = st.chat_input("Ask anything about your file...")
    if message:
        send_message(message, "human")
        chain = (
            {
                "context": keyword_retriever
                | RunnableLambda(
                    lambda docs: "\n\n".join(doc.page_content for doc in docs)
                ),
                "question": RunnablePassthrough(),
            }
            | prompt_keyword
            | llm
        )
        with st.chat_message("ai"):
            content = chain.invoke(message).content
            # ìƒì„±ëœ content í† ëŒ€ë¡œ ì¶”ê°€ RAG ì§„í–‰ 
        chain = (
            {
                "context": place_retriever
                | RunnableLambda(
                    lambda docs: "\n\n".join(doc.page_content for doc in docs)
                ),
                "question": RunnablePassthrough(),
            }
            | prompt_place
            | llm
        )
        with st.chat_message("ai"):
            content = chain.invoke(message).content
else:
    st.session_state["messages"] = []
